{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task2\n",
    "Stock prices time series prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1676.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1655.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1656.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1692.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1703.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1710.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1698.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1721.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1733.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1744.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1744.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1754.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1746.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1752.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1759.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1762.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1771.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1763.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1756.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1761.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1767.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1762.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1770.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1747.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1770.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1771.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1767.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1782.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1790.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1798.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>2874.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>2896.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>2897.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>2914.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>2901.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>2901.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>2896.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>2888.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>2878.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>2871.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>2877.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>2887.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>2888.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>2904.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>2904.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>2888.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>2904.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>2907.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>2930.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>2929.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>2919.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>2915.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>2905.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>2914.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2913.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2924.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2923.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2925.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>2901.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>2885.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            t\n",
       "0     1676.12\n",
       "1     1655.45\n",
       "2     1656.40\n",
       "3     1692.56\n",
       "4     1703.20\n",
       "5     1710.14\n",
       "6     1698.06\n",
       "7     1721.54\n",
       "8     1733.15\n",
       "9     1744.50\n",
       "10    1744.66\n",
       "11    1754.67\n",
       "12    1746.38\n",
       "13    1752.07\n",
       "14    1759.77\n",
       "15    1762.11\n",
       "16    1771.95\n",
       "17    1763.31\n",
       "18    1756.54\n",
       "19    1761.64\n",
       "20    1767.93\n",
       "21    1762.97\n",
       "22    1770.49\n",
       "23    1747.15\n",
       "24    1770.61\n",
       "25    1771.89\n",
       "26    1767.69\n",
       "27    1782.00\n",
       "28    1790.62\n",
       "29    1798.18\n",
       "...       ...\n",
       "1230  2874.69\n",
       "1231  2896.74\n",
       "1232  2897.52\n",
       "1233  2914.04\n",
       "1234  2901.13\n",
       "1235  2901.52\n",
       "1236  2896.72\n",
       "1237  2888.60\n",
       "1238  2878.05\n",
       "1239  2871.68\n",
       "1240  2877.13\n",
       "1241  2887.89\n",
       "1242  2888.92\n",
       "1243  2904.18\n",
       "1244  2904.98\n",
       "1245  2888.80\n",
       "1246  2904.31\n",
       "1247  2907.95\n",
       "1248  2930.75\n",
       "1249  2929.67\n",
       "1250  2919.37\n",
       "1251  2915.56\n",
       "1252  2905.97\n",
       "1253  2914.00\n",
       "1254  2913.98\n",
       "1255  2924.59\n",
       "1256  2923.43\n",
       "1257  2925.51\n",
       "1258  2901.61\n",
       "1259  2885.57\n",
       "\n",
       "[1260 rows x 1 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('sp500_27270.csv')\n",
    "df = df[['SP500']]\n",
    "df.columns = ['t']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1703.20</td>\n",
       "      <td>1692.56</td>\n",
       "      <td>1656.40</td>\n",
       "      <td>1655.45</td>\n",
       "      <td>1676.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1710.14</td>\n",
       "      <td>1703.20</td>\n",
       "      <td>1692.56</td>\n",
       "      <td>1656.40</td>\n",
       "      <td>1655.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1698.06</td>\n",
       "      <td>1710.14</td>\n",
       "      <td>1703.20</td>\n",
       "      <td>1692.56</td>\n",
       "      <td>1656.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1721.54</td>\n",
       "      <td>1698.06</td>\n",
       "      <td>1710.14</td>\n",
       "      <td>1703.20</td>\n",
       "      <td>1692.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1733.15</td>\n",
       "      <td>1721.54</td>\n",
       "      <td>1698.06</td>\n",
       "      <td>1710.14</td>\n",
       "      <td>1703.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1744.50</td>\n",
       "      <td>1733.15</td>\n",
       "      <td>1721.54</td>\n",
       "      <td>1698.06</td>\n",
       "      <td>1710.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1744.66</td>\n",
       "      <td>1744.50</td>\n",
       "      <td>1733.15</td>\n",
       "      <td>1721.54</td>\n",
       "      <td>1698.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1754.67</td>\n",
       "      <td>1744.66</td>\n",
       "      <td>1744.50</td>\n",
       "      <td>1733.15</td>\n",
       "      <td>1721.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1746.38</td>\n",
       "      <td>1754.67</td>\n",
       "      <td>1744.66</td>\n",
       "      <td>1744.50</td>\n",
       "      <td>1733.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1752.07</td>\n",
       "      <td>1746.38</td>\n",
       "      <td>1754.67</td>\n",
       "      <td>1744.66</td>\n",
       "      <td>1744.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1759.77</td>\n",
       "      <td>1752.07</td>\n",
       "      <td>1746.38</td>\n",
       "      <td>1754.67</td>\n",
       "      <td>1744.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1762.11</td>\n",
       "      <td>1759.77</td>\n",
       "      <td>1752.07</td>\n",
       "      <td>1746.38</td>\n",
       "      <td>1754.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1771.95</td>\n",
       "      <td>1762.11</td>\n",
       "      <td>1759.77</td>\n",
       "      <td>1752.07</td>\n",
       "      <td>1746.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1763.31</td>\n",
       "      <td>1771.95</td>\n",
       "      <td>1762.11</td>\n",
       "      <td>1759.77</td>\n",
       "      <td>1752.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1756.54</td>\n",
       "      <td>1763.31</td>\n",
       "      <td>1771.95</td>\n",
       "      <td>1762.11</td>\n",
       "      <td>1759.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1761.64</td>\n",
       "      <td>1756.54</td>\n",
       "      <td>1763.31</td>\n",
       "      <td>1771.95</td>\n",
       "      <td>1762.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1767.93</td>\n",
       "      <td>1761.64</td>\n",
       "      <td>1756.54</td>\n",
       "      <td>1763.31</td>\n",
       "      <td>1771.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1762.97</td>\n",
       "      <td>1767.93</td>\n",
       "      <td>1761.64</td>\n",
       "      <td>1756.54</td>\n",
       "      <td>1763.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1770.49</td>\n",
       "      <td>1762.97</td>\n",
       "      <td>1767.93</td>\n",
       "      <td>1761.64</td>\n",
       "      <td>1756.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1747.15</td>\n",
       "      <td>1770.49</td>\n",
       "      <td>1762.97</td>\n",
       "      <td>1767.93</td>\n",
       "      <td>1761.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1770.61</td>\n",
       "      <td>1747.15</td>\n",
       "      <td>1770.49</td>\n",
       "      <td>1762.97</td>\n",
       "      <td>1767.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1771.89</td>\n",
       "      <td>1770.61</td>\n",
       "      <td>1747.15</td>\n",
       "      <td>1770.49</td>\n",
       "      <td>1762.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1767.69</td>\n",
       "      <td>1771.89</td>\n",
       "      <td>1770.61</td>\n",
       "      <td>1747.15</td>\n",
       "      <td>1770.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1782.00</td>\n",
       "      <td>1767.69</td>\n",
       "      <td>1771.89</td>\n",
       "      <td>1770.61</td>\n",
       "      <td>1747.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1790.62</td>\n",
       "      <td>1782.00</td>\n",
       "      <td>1767.69</td>\n",
       "      <td>1771.89</td>\n",
       "      <td>1770.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1798.18</td>\n",
       "      <td>1790.62</td>\n",
       "      <td>1782.00</td>\n",
       "      <td>1767.69</td>\n",
       "      <td>1771.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1791.53</td>\n",
       "      <td>1798.18</td>\n",
       "      <td>1790.62</td>\n",
       "      <td>1782.00</td>\n",
       "      <td>1767.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1787.87</td>\n",
       "      <td>1791.53</td>\n",
       "      <td>1798.18</td>\n",
       "      <td>1790.62</td>\n",
       "      <td>1782.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1781.37</td>\n",
       "      <td>1787.87</td>\n",
       "      <td>1791.53</td>\n",
       "      <td>1798.18</td>\n",
       "      <td>1790.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1795.85</td>\n",
       "      <td>1781.37</td>\n",
       "      <td>1787.87</td>\n",
       "      <td>1791.53</td>\n",
       "      <td>1798.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>2874.69</td>\n",
       "      <td>2856.98</td>\n",
       "      <td>2861.82</td>\n",
       "      <td>2862.96</td>\n",
       "      <td>2857.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>2896.74</td>\n",
       "      <td>2874.69</td>\n",
       "      <td>2856.98</td>\n",
       "      <td>2861.82</td>\n",
       "      <td>2862.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>2897.52</td>\n",
       "      <td>2896.74</td>\n",
       "      <td>2874.69</td>\n",
       "      <td>2856.98</td>\n",
       "      <td>2861.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>2914.04</td>\n",
       "      <td>2897.52</td>\n",
       "      <td>2896.74</td>\n",
       "      <td>2874.69</td>\n",
       "      <td>2856.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>2901.13</td>\n",
       "      <td>2914.04</td>\n",
       "      <td>2897.52</td>\n",
       "      <td>2896.74</td>\n",
       "      <td>2874.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>2901.52</td>\n",
       "      <td>2901.13</td>\n",
       "      <td>2914.04</td>\n",
       "      <td>2897.52</td>\n",
       "      <td>2896.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>2896.72</td>\n",
       "      <td>2901.52</td>\n",
       "      <td>2901.13</td>\n",
       "      <td>2914.04</td>\n",
       "      <td>2897.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>2888.60</td>\n",
       "      <td>2896.72</td>\n",
       "      <td>2901.52</td>\n",
       "      <td>2901.13</td>\n",
       "      <td>2914.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>2878.05</td>\n",
       "      <td>2888.60</td>\n",
       "      <td>2896.72</td>\n",
       "      <td>2901.52</td>\n",
       "      <td>2901.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>2871.68</td>\n",
       "      <td>2878.05</td>\n",
       "      <td>2888.60</td>\n",
       "      <td>2896.72</td>\n",
       "      <td>2901.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>2877.13</td>\n",
       "      <td>2871.68</td>\n",
       "      <td>2878.05</td>\n",
       "      <td>2888.60</td>\n",
       "      <td>2896.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>2887.89</td>\n",
       "      <td>2877.13</td>\n",
       "      <td>2871.68</td>\n",
       "      <td>2878.05</td>\n",
       "      <td>2888.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>2888.92</td>\n",
       "      <td>2887.89</td>\n",
       "      <td>2877.13</td>\n",
       "      <td>2871.68</td>\n",
       "      <td>2878.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>2904.18</td>\n",
       "      <td>2888.92</td>\n",
       "      <td>2887.89</td>\n",
       "      <td>2877.13</td>\n",
       "      <td>2871.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>2904.98</td>\n",
       "      <td>2904.18</td>\n",
       "      <td>2888.92</td>\n",
       "      <td>2887.89</td>\n",
       "      <td>2877.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>2888.80</td>\n",
       "      <td>2904.98</td>\n",
       "      <td>2904.18</td>\n",
       "      <td>2888.92</td>\n",
       "      <td>2887.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>2904.31</td>\n",
       "      <td>2888.80</td>\n",
       "      <td>2904.98</td>\n",
       "      <td>2904.18</td>\n",
       "      <td>2888.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>2907.95</td>\n",
       "      <td>2904.31</td>\n",
       "      <td>2888.80</td>\n",
       "      <td>2904.98</td>\n",
       "      <td>2904.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>2930.75</td>\n",
       "      <td>2907.95</td>\n",
       "      <td>2904.31</td>\n",
       "      <td>2888.80</td>\n",
       "      <td>2904.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>2929.67</td>\n",
       "      <td>2930.75</td>\n",
       "      <td>2907.95</td>\n",
       "      <td>2904.31</td>\n",
       "      <td>2888.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>2919.37</td>\n",
       "      <td>2929.67</td>\n",
       "      <td>2930.75</td>\n",
       "      <td>2907.95</td>\n",
       "      <td>2904.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>2915.56</td>\n",
       "      <td>2919.37</td>\n",
       "      <td>2929.67</td>\n",
       "      <td>2930.75</td>\n",
       "      <td>2907.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>2905.97</td>\n",
       "      <td>2915.56</td>\n",
       "      <td>2919.37</td>\n",
       "      <td>2929.67</td>\n",
       "      <td>2930.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>2914.00</td>\n",
       "      <td>2905.97</td>\n",
       "      <td>2915.56</td>\n",
       "      <td>2919.37</td>\n",
       "      <td>2929.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2913.98</td>\n",
       "      <td>2914.00</td>\n",
       "      <td>2905.97</td>\n",
       "      <td>2915.56</td>\n",
       "      <td>2919.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2924.59</td>\n",
       "      <td>2913.98</td>\n",
       "      <td>2914.00</td>\n",
       "      <td>2905.97</td>\n",
       "      <td>2915.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2923.43</td>\n",
       "      <td>2924.59</td>\n",
       "      <td>2913.98</td>\n",
       "      <td>2914.00</td>\n",
       "      <td>2905.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2925.51</td>\n",
       "      <td>2923.43</td>\n",
       "      <td>2924.59</td>\n",
       "      <td>2913.98</td>\n",
       "      <td>2914.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>2901.61</td>\n",
       "      <td>2925.51</td>\n",
       "      <td>2923.43</td>\n",
       "      <td>2924.59</td>\n",
       "      <td>2913.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>2885.57</td>\n",
       "      <td>2901.61</td>\n",
       "      <td>2925.51</td>\n",
       "      <td>2923.43</td>\n",
       "      <td>2924.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1256 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            t      t-1      t-2      t-3      t-4\n",
       "4     1703.20  1692.56  1656.40  1655.45  1676.12\n",
       "5     1710.14  1703.20  1692.56  1656.40  1655.45\n",
       "6     1698.06  1710.14  1703.20  1692.56  1656.40\n",
       "7     1721.54  1698.06  1710.14  1703.20  1692.56\n",
       "8     1733.15  1721.54  1698.06  1710.14  1703.20\n",
       "9     1744.50  1733.15  1721.54  1698.06  1710.14\n",
       "10    1744.66  1744.50  1733.15  1721.54  1698.06\n",
       "11    1754.67  1744.66  1744.50  1733.15  1721.54\n",
       "12    1746.38  1754.67  1744.66  1744.50  1733.15\n",
       "13    1752.07  1746.38  1754.67  1744.66  1744.50\n",
       "14    1759.77  1752.07  1746.38  1754.67  1744.66\n",
       "15    1762.11  1759.77  1752.07  1746.38  1754.67\n",
       "16    1771.95  1762.11  1759.77  1752.07  1746.38\n",
       "17    1763.31  1771.95  1762.11  1759.77  1752.07\n",
       "18    1756.54  1763.31  1771.95  1762.11  1759.77\n",
       "19    1761.64  1756.54  1763.31  1771.95  1762.11\n",
       "20    1767.93  1761.64  1756.54  1763.31  1771.95\n",
       "21    1762.97  1767.93  1761.64  1756.54  1763.31\n",
       "22    1770.49  1762.97  1767.93  1761.64  1756.54\n",
       "23    1747.15  1770.49  1762.97  1767.93  1761.64\n",
       "24    1770.61  1747.15  1770.49  1762.97  1767.93\n",
       "25    1771.89  1770.61  1747.15  1770.49  1762.97\n",
       "26    1767.69  1771.89  1770.61  1747.15  1770.49\n",
       "27    1782.00  1767.69  1771.89  1770.61  1747.15\n",
       "28    1790.62  1782.00  1767.69  1771.89  1770.61\n",
       "29    1798.18  1790.62  1782.00  1767.69  1771.89\n",
       "30    1791.53  1798.18  1790.62  1782.00  1767.69\n",
       "31    1787.87  1791.53  1798.18  1790.62  1782.00\n",
       "32    1781.37  1787.87  1791.53  1798.18  1790.62\n",
       "33    1795.85  1781.37  1787.87  1791.53  1798.18\n",
       "...       ...      ...      ...      ...      ...\n",
       "1230  2874.69  2856.98  2861.82  2862.96  2857.05\n",
       "1231  2896.74  2874.69  2856.98  2861.82  2862.96\n",
       "1232  2897.52  2896.74  2874.69  2856.98  2861.82\n",
       "1233  2914.04  2897.52  2896.74  2874.69  2856.98\n",
       "1234  2901.13  2914.04  2897.52  2896.74  2874.69\n",
       "1235  2901.52  2901.13  2914.04  2897.52  2896.74\n",
       "1236  2896.72  2901.52  2901.13  2914.04  2897.52\n",
       "1237  2888.60  2896.72  2901.52  2901.13  2914.04\n",
       "1238  2878.05  2888.60  2896.72  2901.52  2901.13\n",
       "1239  2871.68  2878.05  2888.60  2896.72  2901.52\n",
       "1240  2877.13  2871.68  2878.05  2888.60  2896.72\n",
       "1241  2887.89  2877.13  2871.68  2878.05  2888.60\n",
       "1242  2888.92  2887.89  2877.13  2871.68  2878.05\n",
       "1243  2904.18  2888.92  2887.89  2877.13  2871.68\n",
       "1244  2904.98  2904.18  2888.92  2887.89  2877.13\n",
       "1245  2888.80  2904.98  2904.18  2888.92  2887.89\n",
       "1246  2904.31  2888.80  2904.98  2904.18  2888.92\n",
       "1247  2907.95  2904.31  2888.80  2904.98  2904.18\n",
       "1248  2930.75  2907.95  2904.31  2888.80  2904.98\n",
       "1249  2929.67  2930.75  2907.95  2904.31  2888.80\n",
       "1250  2919.37  2929.67  2930.75  2907.95  2904.31\n",
       "1251  2915.56  2919.37  2929.67  2930.75  2907.95\n",
       "1252  2905.97  2915.56  2919.37  2929.67  2930.75\n",
       "1253  2914.00  2905.97  2915.56  2919.37  2929.67\n",
       "1254  2913.98  2914.00  2905.97  2915.56  2919.37\n",
       "1255  2924.59  2913.98  2914.00  2905.97  2915.56\n",
       "1256  2923.43  2924.59  2913.98  2914.00  2905.97\n",
       "1257  2925.51  2923.43  2924.59  2913.98  2914.00\n",
       "1258  2901.61  2925.51  2923.43  2924.59  2913.98\n",
       "1259  2885.57  2901.61  2925.51  2923.43  2924.59\n",
       "\n",
       "[1256 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Time Series\n",
    "for i in range(1,5):\n",
    "    df['t-{}'.format(i)] = df['t'].shift(i)\n",
    "\n",
    "# Drop NaNs\n",
    "df.drop(df.head(4).index, inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(df.values[:-1]).astype(np.float16)\n",
    "y = np.array(df['t'].shift(-1).values[:-1]).astype(np.float16)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Indicate the scoring metric suitable for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a Regression problem the choices are:\n",
    "\t \n",
    "| Metric                       | Sklearn Function                 |\n",
    "|------------------------------|----------------------------------|\n",
    "| â€˜explained_varianceâ€™         | metrics.explained_variance_score |\n",
    "| â€˜neg_mean_absolute_errorâ€™    | metrics.mean_absolute_error      |\n",
    "| â€˜neg_mean_squared_errorâ€™     | metrics.mean_squared_error       |\n",
    "| â€˜neg_mean_squared_log_errorâ€™ | metrics.mean_squared_log_error   |\n",
    "| â€˜neg_median_absolute_errorâ€™  | metrics.median_absolute_error    |\n",
    "| â€˜r2â€™                         | metrics.r2_score                 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scoring = make_scorer(metrics.mean_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Indicate the neural network architecture and configuration that achieve the best score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(validation_fraction=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate_init': 0.001}\n"
     ]
    }
   ],
   "source": [
    "learning_rates = dict([('learning_rate_init', [0.001, 0.01, 0.1, 0.2, 0.5])])\n",
    "gs_lr = GridSearchCV(clf, param_grid=learning_rates, scoring=scoring, verbose=0, n_jobs=-1)\n",
    "gs_lr.fit(X_train, y_train)\n",
    "print(gs_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layer_sizes': (128,)}\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = dict([('hidden_layer_sizes', [(128,), (512,), (1024,), (128, 128), (128, 128, 128)])])\n",
    "gs_layers = GridSearchCV(clf, param_grid=hidden_layers, scoring=scoring, verbose=0, n_jobs=-1)\n",
    "gs_layers.fit(X_train, y_train)\n",
    "print(gs_layers.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:358: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\"Got `batch_size` less than 1 or larger than \"\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = dict([('batch_size', [32, 64, 256, 512])])\n",
    "gs_batch = GridSearchCV(clf, param_grid=batch_sizes, scoring=scoring, verbose=0, n_jobs=-1)\n",
    "gs_batch.fit(X_train, y_train)\n",
    "print(gs_batch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "alphas = dict([('alpha', [0.0001, 0.001, 0.01, 0.1])])\n",
    "gs_alpha = GridSearchCV(clf, param_grid=alphas, scoring=scoring, verbose=0, n_jobs=-1)\n",
    "gs_alpha.fit(X_train, y_train)\n",
    "print(gs_alpha.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['32', '64', '256', '512']\n",
      "['0.0001', '0.001', '0.01', '0.1']\n",
      "['(128,)', '(512,)', '(1024,)', '(128, 128)', '(128, 128, 128)']\n",
      "['0.001', '0.01', '0.1', '0.2', '0.5']\n",
      "Best Batch Size: ['1' '471.04158366533864' '32']\n",
      "Worst Batch Size: ['4' '284.94596613545815' '64']\n",
      "\n",
      "Best Hidden Layers: ['1' '344.63894422310756' '(128,)']\n",
      "WorstHidden Layers: ['5' '249.2339392430279' '(128, 128, 128)']\n",
      "\n",
      "Best Learning Rate: ['1' '324.2791334661355' '0.001']\n",
      "Worst Learning Rate: ['5' '248.10296314741035' '0.1']\n",
      "\n",
      "Best L2 Value: ['1' '316.507719123506' '0.0001']\n",
      "Worst L2 Value: ['4' '261.976593625498' '0.01']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from helpers import results_parser\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "res_batch = results_parser(gs_batch)\n",
    "res_batch = np.array(res_batch)\n",
    "\n",
    "res_alpha = results_parser(gs_alpha)\n",
    "res_alpha = np.array(res_alpha)\n",
    "\n",
    "res_layers = results_parser(gs_layers)\n",
    "res_layers = np.array(res_layers)\n",
    "\n",
    "res_lr = results_parser(gs_lr)\n",
    "res_lr = np.array(res_lr)\n",
    "\n",
    "print('Best Batch Size:', res_batch[0])\n",
    "print('Worst Batch Size:', res_batch[-1])\n",
    "print()\n",
    "\n",
    "print('Best Hidden Layers:', res_layers[0])\n",
    "print('WorstHidden Layers:', res_layers[-1])\n",
    "print()\n",
    "\n",
    "print('Best Learning Rate:', res_lr[0])\n",
    "print('Worst Learning Rate:', res_lr[-1])\n",
    "print()\n",
    "\n",
    "print('Best L2 Value:', res_alpha[0])\n",
    "print('Worst L2 Value:', res_alpha[-1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size=32, beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(128,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.25,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "best_batch_size = int(res_batch[0][-1])\n",
    "best_lr = float(res_lr[0][-1])\n",
    "best_alpha = float(res_alpha[0][-1])\n",
    "best_layers = literal_eval(res_layers[0][-1])\n",
    "\n",
    "clf_best = MLPClassifier(\n",
    "    validation_fraction=0.25,\n",
    "    early_stopping=True,\n",
    "    batch_size=best_batch_size,\n",
    "    hidden_layer_sizes=best_layers,\n",
    "    learning_rate_init=best_lr,\n",
    "    alpha=best_alpha\n",
    ")\n",
    "\n",
    "clf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/miniconda3/envs/bachelor/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size=32, beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(128,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.25,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use the trained neural network to predict stock price for 3 instances from the test set. Display the output value versus the predicted value and justify the similarities and differences in values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf_best.predict(X_test[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = range(0, 3)\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "plt.plot(x, pred, 'o')\n",
    "plt.plot(x, y_test[0:3], 'o')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
